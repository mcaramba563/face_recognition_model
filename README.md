# Face Recognition Project

Проект для распознавания лиц и генерации эмбеддингов с использованием ArcFace и других моделей.
Задача проекта - получить эмбединг всех лиц, содержащихся на изображении.


## Структура проекта
- `notebooks/` - Jupyter-ноутбуки с исследованиями и пайплайнами
- `models/` - Предобученные модели

## Использование
Основные ноутбуки:
- `face-recognition-full-pipeline.ipynb` - Примеры выравнивания лиц по ключавым точкам(глазам) и получение его эмбединга
- `arcface-model.ipynb` - обучение модели для генерации эмбедингов заалайненых лиц
- `face-key-points.ipynb` - Детекция ключевых точек

## Модели
- `face_emb_model` - Модель для генерации эмбеддингов лиц
- `eyes_model_v3.pt` - Модель для детекции глаз


# Face embedding model
Сначала я обучил модель для генерации эьбедингов для уже кропнутых и заалайненых лиц.
В качестве модели я взял resnet101 и обучал на лоссе arcface для лучшего распределения эмбедингов.

![alt text](images/image-1.png)

Датасет для обучения модели представлял из себя урезанный celeba(до 500 классов).
Датасет для измерения метрики - изображения лиц, не присутствующие в датасете.

В качестве аугментаций использовались Color jitter и Random horizontal flip.

Измеряемая метрика - Identification rate.
Полученные результаты:
IR metric:
| False Positive rate  | Left Threshold  | True Positive Rate |
| -------- | --------- |:---------:|
|   0.05   |    0.236  |   0.465   |
|   0.1    |    0.193  |   0.588   |
|   0.2    |    0.146  |   0.725   |

![alt text](images/image-2.png)

## Face keypoints detection model
Здесь простая модель resnet50, обученная на датасете helen на поиск ключевых точек глаз(всего 12 точек).

В качестве аугментаций использовались случайная обрезка изображения, Color jitter и поворот.

Координаты точек нормировались на размеры изображения.
Обучалась модель на MSE Loss

Результат(синие точки предсказаны моделью):
![alt text](images/image-3.png)

## Full pipeline
1. Детектируем лицо с помощью модели YOLOv8
2. Обрезаем изображение
3. Находим координаты глаз
4. Выравнивыем лицо, чтобы глаза были парралельны горизонтали
5. Подаем лица на вход модели, которая выдаст нам эмбединг

Похожесь лиц можно определить как косинусную близость между ними(между эмбедингов лиц одного человека она должна быть больше, чем между лицами разных людей)
```
def cos_sim(a, b):
    dot_product = np.dot(a, b)
    norm_a = np.linalg.norm(a)
    norm_b = np.linalg.norm(b)
    if norm_a == 0 or norm_b == 0:
        return 0.0
    return dot_product / (norm_a * norm_b)
```

### Несколько примеров

![alt text](images/image-4.png)

![alt text](images/image-5.png)

![alt text](images/image-6.png)

Видим пары фотографий(до выравнивания и после, также обозначены ключевые точки глаз)
Последние две пары принедлежат одному классу, а первая другому

```
print(cos_sim(emb_10046_1[0][0],emb_10046_2[0][0]), cos_sim(emb_121[0][0],emb_10046_1[0][0]), cos_sim(emb_121[0][0],emb_10046_2[0][0]))
0.19941421 -0.0013863962 0.13440342
```

![alt text](images/image-7.png)

![alt text](images/image-8.png)

![alt text](images/image-9.png)

```
print(cos_sim(emb_2507_1[0][0],emb_2507_2[0][0]), cos_sim(emb_2507_1[0][0],emb_1212[0][0]), cos_sim(emb_2507_2[0][0],emb_1212[0][0]))
0.38638577 0.1703509 -0.005291564
```

Из косинусной близости изображений видим, что вектора одного класса ближе друг к другу(угол между ними меньше), чем между разными.